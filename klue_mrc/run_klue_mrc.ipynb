{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d2c1f6-cdb1-40df-b5df-2efe81b471a0",
   "metadata": {},
   "source": [
    "# Running the KLUE MRC (Machine Reading Comprehension) Benchmark\n",
    "\n",
    "## Ensure `klue_mrc` is the current working directory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efaae47f-aed1-4327-a0af-02905cc78f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/google/home/thekim/github/aimldl/llm_benchmarks_asian_langs/klue_mrc'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8827fecd-ff3f-41e3-8d14-e1bcb22b8328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABOUT_KLUE_MRC.md   \u001b[0m\u001b[01;34meval_dataset\u001b[0m/               \u001b[01;32mrun\u001b[0m*\n",
      "HISTORY.md          \u001b[01;32mget_errors.sh\u001b[0m*              run_klue_mrc.ipynb\n",
      "README.md           \u001b[01;32minstall_dependencies.sh\u001b[0m*    \u001b[01;32msetup.sh\u001b[0m*\n",
      "TROUBLESHOOTING.md  klue_mrc-gemini2_5flash.py  \u001b[01;32mtest_logging.sh\u001b[0m*\n",
      "VERTEX_AI_SETUP.md  \u001b[01;34mlogs\u001b[0m/                       test_rouge.py\n",
      "\u001b[01;34m__pycache__\u001b[0m/        requirements.txt            test_setup.py\n",
      "\u001b[01;34mbenchmark_results\u001b[0m/  \u001b[01;34mresult_analysis\u001b[0m/            \u001b[01;32mverify_scripts.sh\u001b[0m*\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24c70d5-c26c-451d-9381-cf0dc38bf54f",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25b7fdbd-b93d-45cb-af90-dedb6e4f8af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;34m[INFO]\u001b[0m Checking prerequisites...\n",
      "\u001b[0;32m[SUCCESS]\u001b[0m Prerequisites check passed\n",
      "\u001b[0;34m[INFO]\u001b[0m Installing Python dependencies...\n",
      "\u001b[0;32m[SUCCESS]\u001b[0m Dependencies installed successfully!\n",
      "\u001b[0;34m[INFO]\u001b[0m Testing the setup...\n",
      "============================================================\n",
      "KLUE MRC Benchmark Setup Test (Vertex AI)\n",
      "============================================================\n",
      "Testing package imports...\n",
      "✓ google.cloud.aiplatform\n",
      "✓ vertexai\n",
      "✓ datasets\n",
      "✓ pandas\n",
      "✓ tqdm\n",
      "✓ huggingface_hub\n",
      "✓ google.auth\n",
      "\n",
      "✅ All packages imported successfully!\n",
      "\n",
      "Testing environment variables...\n",
      "✓ GOOGLE_CLOUD_PROJECT: vertex-workbench-notebook\n",
      "⚠ GOOGLE_APPLICATION_CREDENTIALS: Not set (using default credentials)\n",
      "\n",
      "Testing KLUE MRC dataset loading...\n",
      "✓ KLUE mrc dataset for MRC loaded successfully\n",
      "  - Train samples: 17554\n",
      "  - Validation samples: 5841\n",
      "  - Sample from validation set:\n",
      "    - Title: BMW 코리아, 창립 25주년 기념 ‘BMW 코리아 25주년 에디션’ 한정 출시\n",
      "    - Context: BMW 코리아(대표 한상윤)는 창립 25주년을 기념하는 ‘BMW 코리아 25주년 에디션’을 한정 출시한다고 밝혔다. 이번 BMW 코리아 25주년 에디션(이하 25주년 에디션)은 B...\n",
      "    - Question: 말라카이트에서 나온 색깔을 사용한 에디션은?\n",
      "    - Answers: {'answer_start': [666, 666], 'text': ['뉴 740Li 25주년 에디션', '뉴 740Li 25주년']}\n",
      "    - Is Impossible: False\n",
      "\n",
      "Testing Vertex AI authentication...\n",
      "✓ Credentials found\n",
      "  - Project: vertex-workbench-notebook\n",
      "  - Credentials type: Credentials\n",
      "✓ Vertex AI initialization works\n",
      "\n",
      "Testing ROUGE-W and LCCS-F1 metrics...\n",
      "project_id: vertex-workbench-notebook\n",
      "2025-07-15 18:06:22,586 - INFO - Initialized Vertex AI with project: vertex-workbench-notebook, location: us-central1\n",
      "2025-07-15 18:06:22,586 - INFO - Model name set to: gemini-2.5-flash\n",
      "✓ ROUGE-W and LCCS-F1 metrics calculation works\n",
      "  - Reference: 노르웨이로 파견되었다\n",
      "  - Prediction: 노르웨이\n",
      "  - ROUGE-W: 0.0000\n",
      "  - LCCS-F1: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test Summary\n",
      "============================================================\n",
      "✅ All tests passed! Your setup is ready.\n",
      "\n",
      "Next steps:\n",
      "1. Ensure your Google Cloud project has Vertex AI API enabled\n",
      "2. Set project ID: export GOOGLE_CLOUD_PROJECT='your-project-id'\n",
      "3. Run the benchmark: python klue_mrc-gemini2_5flash.py --project-id 'your-project-id'\n",
      "\u001b[0;32m[SUCCESS]\u001b[0m Setup test completed successfully!\n",
      "\n",
      "\u001b[0;34m[INFO]\u001b[0m Next steps for Vertex AI setup:\n",
      "1. Install Google Cloud CLI: https://cloud.google.com/sdk/docs/install\n",
      "2. Authenticate with gcloud: gcloud auth login\n",
      "3. Set up application default credentials: gcloud auth application-default login\n",
      "4. Set your project ID: export GOOGLE_CLOUD_PROJECT='your-project-id'\n",
      "5. Enable Vertex AI API: gcloud services enable aiplatform.googleapis.com\n",
      "6. Run the benchmark: ./run test (for small test) or ./run full (for full benchmark)\n",
      "\n",
      "\u001b[0;34m[INFO]\u001b[0m Logging features:\n",
      "- All benchmark runs are automatically logged to the 'logs/' directory\n",
      "- Log files include command headers for easy identification\n",
      "- Separate error logs (.err) are created for focused debugging\n"
     ]
    }
   ],
   "source": [
    "!./setup.sh full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f019c70b-c9e5-42ca-9a94-9228a44bcfb5",
   "metadata": {},
   "source": [
    "### Test-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb9dc522-2977-462e-892d-f3c79e94ffad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test benchmark with 10 samples...\n",
      "2025-07-15 18:07:38,622 - INFO - Initialized Vertex AI with project: vertex-workbench-notebook, location: us-central1\n",
      "2025-07-15 18:07:38,622 - INFO - Model name set to: gemini-2.5-flash\n",
      "2025-07-15 18:07:38,622 - INFO - Loading KLUE MRC dataset for machine reading comprehension...\n",
      "2025-07-15 18:07:51,757 - INFO - Preparing to load a subset of 10 samples.\n",
      "2025-07-15 18:07:51,759 - INFO - Reached sample limit of 10. Halting data loading.\n",
      "2025-07-15 18:07:51,759 - INFO - ✅ Successfully loaded 10 samples.\n",
      "2025-07-15 18:07:51,759 - INFO - Starting benchmark...\n",
      "project_id: vertex-workbench-notebook\n",
      "Processing samples:   0%|          | 0/10 [00:00<?, ?it/s]2025-07-15 18:07:51,759 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 18:07:54,790 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 18:07:54,791 - INFO - AFC remote call 1 is done.\n",
      "Processing samples:  10%|█         | 1/10 [00:03<00:27,  3.07s/it]2025-07-15 18:07:54,832 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 18:07:57,151 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 18:07:57,152 - INFO - AFC remote call 1 is done.\n",
      "Processing samples:  20%|██        | 2/10 [00:05<00:21,  2.65s/it]2025-07-15 18:07:57,193 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 18:07:59,346 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 18:07:59,347 - INFO - AFC remote call 1 is done.\n",
      "Processing samples:  30%|███       | 3/10 [00:07<00:17,  2.44s/it]2025-07-15 18:07:59,387 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 18:08:00,827 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 18:08:00,829 - INFO - AFC remote call 1 is done.\n",
      "Processing samples:  40%|████      | 4/10 [00:09<00:12,  2.06s/it]2025-07-15 18:08:00,869 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 18:08:02,611 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 18:08:02,612 - INFO - AFC remote call 1 is done.\n",
      "Processing samples:  50%|█████     | 5/10 [00:10<00:09,  1.96s/it]2025-07-15 18:08:02,652 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 18:08:04,239 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 18:08:04,240 - INFO - AFC remote call 1 is done.\n",
      "Processing samples:  60%|██████    | 6/10 [00:12<00:07,  1.85s/it]2025-07-15 18:08:04,281 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 18:08:05,937 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 18:08:05,938 - INFO - AFC remote call 1 is done.\n",
      "Processing samples:  70%|███████   | 7/10 [00:14<00:05,  1.80s/it]2025-07-15 18:08:05,979 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 18:08:07,411 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 18:08:07,412 - INFO - AFC remote call 1 is done.\n",
      "Processing samples:  80%|████████  | 8/10 [00:15<00:03,  1.70s/it]2025-07-15 18:08:07,453 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 18:08:10,156 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 18:08:10,157 - INFO - AFC remote call 1 is done.\n",
      "Processing samples:  90%|█████████ | 9/10 [00:18<00:02,  2.02s/it]2025-07-15 18:08:10,198 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 18:08:11,605 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 18:08:11,607 - INFO - AFC remote call 1 is done.\n",
      "Processing samples: 100%|██████████| 10/10 [00:19<00:00,  1.99s/it]\n",
      "2025-07-15 18:08:11,648 - INFO - Benchmark completed!\n",
      "2025-07-15 18:08:11,648 - INFO - Exact Match: 1.0000\n",
      "2025-07-15 18:08:11,648 - INFO - F1 Score: 1.0000\n",
      "2025-07-15 18:08:11,648 - INFO - ROUGE-W: 0.9958\n",
      "2025-07-15 18:08:11,648 - INFO - LCCS-F1: 0.9000\n",
      "2025-07-15 18:08:11,648 - INFO - Impossible Accuracy: 1.0000\n",
      "2025-07-15 18:08:11,648 - INFO - Total time: 19.89 seconds\n",
      "2025-07-15 18:08:11,648 - INFO - Average time per sample: 1.989 seconds\n",
      "2025-07-15 18:08:11,649 - INFO - Metrics saved to: benchmark_results/klue_mrc_metrics_20250715_180811.json\n",
      "2025-07-15 18:08:11,650 - INFO - Detailed results saved to: benchmark_results/klue_mrc_results_20250715_180811.json\n",
      "2025-07-15 18:08:11,653 - INFO - Results saved as CSV: benchmark_results/klue_mrc_results_20250715_180811.csv\n",
      "2025-07-15 18:08:11,653 - INFO - No errors to analyze\n",
      "============================================================\n",
      "KLUE Machine Reading Comprehension Benchmark Results\n",
      "============================================================\n",
      "Model: gemini-2.5-flash\n",
      "Platform: Google Cloud Vertex AI\n",
      "Project: vertex-workbench-notebook\n",
      "Location: us-central1\n",
      "Exact Match: 1.0000\n",
      "F1 Score: 1.0000\n",
      "ROUGE-W: 0.9958\n",
      "LCCS-F1: 0.9000\n",
      "Impossible Accuracy: 1.0000\n",
      "Total Samples: 10\n",
      "Answerable Samples: 8\n",
      "Impossible Samples: 2\n",
      "Total Time: 19.89 seconds\n",
      "Average Time per Sample: 1.989 seconds\n",
      "Samples per Second: 0.50\n",
      "\n",
      "Answerable Questions Performance:\n",
      "  Exact Match: 1.0000\n",
      "  F1 Score: 1.0000\n",
      "  ROUGE-W: 0.9948\n",
      "  LCCS-F1: 0.8750\n",
      "  Sample Count: 8\n",
      "\n",
      "Impossible Questions Performance:\n",
      "  Accuracy: 1.0000\n",
      "  Correct: 2/2\n",
      "\n",
      "Log files saved:\n",
      "  Full output: logs/klue_mrc_test_20250715_180737.log\n",
      "  Errors only: logs/klue_mrc_test_20250715_180737.err\n"
     ]
    }
   ],
   "source": [
    "!./run test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb5d028-76a8-4ff0-8737-a2fb73d73b11",
   "metadata": {},
   "source": [
    "#### Test with More Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47e7096a-3323-4a9b-9f0b-85eebfb0ff82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running custom benchmark with 100 samples...\n",
      "2025-07-15 12:54:54,534 - INFO - Initialized Vertex AI with project: vertex-workbench-notebook, location: us-central1\n",
      "2025-07-15 12:54:54,534 - INFO - Model name set to: gemini-2.5-flash\n",
      "2025-07-15 12:54:54,535 - INFO - Loading KLUE MRC dataset for machine reading comprehension...\n",
      "2025-07-15 12:55:05,001 - INFO - Preparing to load a subset of 100 samples.\n",
      "2025-07-15 12:55:05,009 - INFO - Reached sample limit of 100. Halting data loading.\n",
      "2025-07-15 12:55:05,009 - INFO - ✅ Successfully loaded 100 samples.\n",
      "2025-07-15 12:55:05,009 - INFO - Starting benchmark...\n",
      "project_id: vertex-workbench-notebook\n",
      "Processing samples:   0%|          | 0/100 [00:00<?, ?it/s]2025-07-15 12:55:05,010 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:55:08,848 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:55:08,849 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:55:08,849 - INFO - Using default tokenizer.\n",
      "Processing samples:   1%|          | 1/100 [00:03<06:24,  3.88s/it]2025-07-15 12:55:08,890 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:55:11,117 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:55:11,118 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:55:11,118 - INFO - Using default tokenizer.\n",
      "Processing samples:   2%|▏         | 2/100 [00:06<04:47,  2.93s/it]2025-07-15 12:55:11,159 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:55:13,654 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:55:13,655 - INFO - AFC remote call 1 is done.\n",
      "Processing samples:   3%|▎         | 3/100 [00:08<04:26,  2.75s/it]2025-07-15 12:55:13,695 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:55:14,981 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:55:14,983 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:55:14,983 - INFO - Using default tokenizer.\n",
      "Processing samples:   4%|▍         | 4/100 [00:10<03:30,  2.19s/it]2025-07-15 12:55:15,023 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:55:16,788 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:55:16,789 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:55:16,789 - INFO - Using default tokenizer.\n",
      "Processing samples:   5%|▌         | 5/100 [00:11<03:14,  2.05s/it]2025-07-15 12:55:16,829 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:55:18,288 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:55:18,289 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:55:18,289 - INFO - Using default tokenizer.\n",
      "Processing samples:   6%|▌         | 6/100 [00:13<02:55,  1.86s/it]2025-07-15 12:55:18,330 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:55:19,885 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:55:19,886 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:55:19,886 - INFO - Using default tokenizer.\n",
      "Processing samples:   7%|▋         | 7/100 [00:14<02:45,  1.78s/it]2025-07-15 12:55:19,926 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:55:21,227 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:55:21,228 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:55:21,228 - INFO - Using default tokenizer.\n",
      "Processing samples:   8%|▊         | 8/100 [00:16<02:30,  1.64s/it]2025-07-15 12:55:21,269 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:55:25,174 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:55:25,175 - INFO - AFC remote call 1 is done.\n",
      "Processing samples:   9%|▉         | 9/100 [00:20<03:34,  2.36s/it]2025-07-15 12:55:25,216 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:55:26,520 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:55:26,523 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:55:26,523 - INFO - Using default tokenizer.\n",
      "Processing samples:  10%|█         | 10/100 [00:21<03:04,  2.05s/it]2025-07-15 12:55:26,563 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:55:41,019 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:55:41,022 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:55:41,022 - ERROR - Cannot get the response text.\n",
      "Processing samples:  11%|█         | 11/100 [00:36<08:41,  5.86s/it]2025-07-15 12:55:41,062 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:55:49,550 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:55:49,553 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:55:49,553 - INFO - Using default tokenizer.\n",
      "Processing samples:  12%|█▏        | 12/100 [00:44<09:47,  6.67s/it]2025-07-15 12:55:49,593 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:55:50,668 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:55:50,670 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:55:50,670 - INFO - Using default tokenizer.\n",
      "Processing samples:  13%|█▎        | 13/100 [00:45<07:14,  4.99s/it]2025-07-15 12:55:50,711 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:55:51,806 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:55:51,807 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:55:51,807 - INFO - Using default tokenizer.\n",
      "Processing samples:  14%|█▍        | 14/100 [00:46<05:28,  3.83s/it]2025-07-15 12:55:51,847 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:55:53,127 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:55:53,128 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:55:53,128 - INFO - Using default tokenizer.\n",
      "Processing samples:  15%|█▌        | 15/100 [00:48<04:20,  3.07s/it]2025-07-15 12:55:53,169 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:55:54,740 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:55:54,741 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:55:54,741 - INFO - Using default tokenizer.\n",
      "Processing samples:  16%|█▌        | 16/100 [00:49<03:41,  2.63s/it]2025-07-15 12:55:54,782 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:55:56,894 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:55:56,895 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:55:56,896 - INFO - Using default tokenizer.\n",
      "Processing samples:  17%|█▋        | 17/100 [00:51<03:26,  2.49s/it]2025-07-15 12:55:56,936 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:56:01,603 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:56:01,605 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:56:01,606 - INFO - Using default tokenizer.\n",
      "Processing samples:  18%|█▊        | 18/100 [00:56<04:18,  3.16s/it]2025-07-15 12:56:01,646 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:56:04,363 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:56:04,364 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:56:04,364 - INFO - Using default tokenizer.\n",
      "Processing samples:  19%|█▉        | 19/100 [00:59<04:05,  3.04s/it]2025-07-15 12:56:04,404 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:56:14,200 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:56:14,202 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:56:14,202 - INFO - Using default tokenizer.\n",
      "Processing samples:  20%|██        | 20/100 [01:09<06:46,  5.08s/it]2025-07-15 12:56:14,243 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:56:15,797 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:56:15,800 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:56:15,800 - INFO - Using default tokenizer.\n",
      "Processing samples:  21%|██        | 21/100 [01:10<05:18,  4.03s/it]2025-07-15 12:56:15,840 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:56:17,935 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:56:17,938 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:56:17,938 - INFO - Using default tokenizer.\n",
      "Processing samples:  22%|██▏       | 22/100 [01:12<04:30,  3.46s/it]2025-07-15 12:56:17,978 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:56:20,777 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:56:20,780 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:56:20,780 - INFO - Using default tokenizer.\n",
      "Processing samples:  23%|██▎       | 23/100 [01:15<04:12,  3.28s/it]2025-07-15 12:56:20,820 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:56:22,710 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:56:22,713 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:56:22,713 - INFO - Using default tokenizer.\n",
      "Processing samples:  24%|██▍       | 24/100 [01:17<03:38,  2.87s/it]2025-07-15 12:56:22,753 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:56:26,704 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:56:26,707 - INFO - AFC remote call 1 is done.\n",
      "Processing samples:  25%|██▌       | 25/100 [01:21<04:00,  3.21s/it]2025-07-15 12:56:26,747 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:56:30,077 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:56:30,079 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:56:30,079 - INFO - Using default tokenizer.\n",
      "Processing samples:  26%|██▌       | 26/100 [01:25<04:01,  3.26s/it]2025-07-15 12:56:30,120 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:56:34,322 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:56:34,324 - INFO - AFC remote call 1 is done.\n",
      "Processing samples:  27%|██▋       | 27/100 [01:29<04:19,  3.55s/it]2025-07-15 12:56:34,365 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:56:37,381 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:56:37,383 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:56:37,383 - INFO - Using default tokenizer.\n",
      "Processing samples:  28%|██▊       | 28/100 [01:32<04:05,  3.41s/it]2025-07-15 12:56:37,424 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:56:40,040 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:56:40,043 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:56:40,043 - INFO - Using default tokenizer.\n",
      "Processing samples:  29%|██▉       | 29/100 [01:35<03:45,  3.18s/it]2025-07-15 12:56:40,083 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:56:42,575 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:56:42,578 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:56:42,578 - INFO - Using default tokenizer.\n",
      "Processing samples:  30%|███       | 30/100 [01:37<03:29,  2.99s/it]2025-07-15 12:56:42,618 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:56:47,115 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:56:47,117 - INFO - AFC remote call 1 is done.\n",
      "Processing samples:  31%|███       | 31/100 [01:42<03:58,  3.45s/it]2025-07-15 12:56:47,158 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:56:48,221 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:56:48,224 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:56:48,224 - INFO - Using default tokenizer.\n",
      "Processing samples:  32%|███▏      | 32/100 [01:43<03:06,  2.75s/it]2025-07-15 12:56:48,265 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:56:49,671 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:56:49,674 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:56:49,674 - INFO - Using default tokenizer.\n",
      "Processing samples:  33%|███▎      | 33/100 [01:44<02:38,  2.36s/it]2025-07-15 12:56:49,714 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:56:57,966 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:56:57,969 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:56:57,969 - INFO - Using default tokenizer.\n",
      "Processing samples:  34%|███▍      | 34/100 [01:52<04:33,  4.14s/it]2025-07-15 12:56:58,009 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:57:06,568 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:57:06,571 - INFO - AFC remote call 1 is done.\n",
      "Processing samples:  35%|███▌      | 35/100 [02:01<05:56,  5.48s/it]2025-07-15 12:57:06,611 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:57:11,820 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:57:11,822 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:57:11,823 - INFO - Using default tokenizer.\n",
      "Processing samples:  36%|███▌      | 36/100 [02:06<05:46,  5.41s/it]2025-07-15 12:57:11,863 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:57:13,759 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:57:13,761 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:57:13,761 - INFO - Using default tokenizer.\n",
      "Processing samples:  37%|███▋      | 37/100 [02:08<04:35,  4.37s/it]2025-07-15 12:57:13,802 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:57:15,247 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:57:15,250 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:57:15,250 - INFO - Using default tokenizer.\n",
      "Processing samples:  38%|███▊      | 38/100 [02:10<03:37,  3.50s/it]2025-07-15 12:57:15,290 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:57:22,487 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:57:22,490 - INFO - AFC remote call 1 is done.\n",
      "Processing samples:  39%|███▉      | 39/100 [02:17<04:42,  4.63s/it]2025-07-15 12:57:22,530 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:57:24,596 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:57:24,599 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:57:24,599 - INFO - Using default tokenizer.\n",
      "Processing samples:  40%|████      | 40/100 [02:19<03:52,  3.87s/it]2025-07-15 12:57:24,639 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:57:25,835 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:57:25,837 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:57:25,838 - INFO - Using default tokenizer.\n",
      "Processing samples:  41%|████      | 41/100 [02:20<03:01,  3.08s/it]2025-07-15 12:57:25,878 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:57:26,864 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:57:26,867 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:57:26,867 - INFO - Using default tokenizer.\n",
      "Processing samples:  42%|████▏     | 42/100 [02:21<02:22,  2.47s/it]2025-07-15 12:57:26,907 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:57:31,515 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:57:31,517 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:57:31,517 - INFO - Using default tokenizer.\n",
      "Processing samples:  43%|████▎     | 43/100 [02:26<02:57,  3.12s/it]2025-07-15 12:57:31,558 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:57:34,988 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:57:34,991 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:57:34,992 - INFO - Using default tokenizer.\n",
      "Processing samples:  44%|████▍     | 44/100 [02:30<03:00,  3.23s/it]2025-07-15 12:57:35,032 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:57:40,335 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:57:40,338 - INFO - AFC remote call 1 is done.\n",
      "Processing samples:  45%|████▌     | 45/100 [02:35<03:32,  3.86s/it]2025-07-15 12:57:40,378 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:57:42,186 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:57:42,188 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:57:42,189 - INFO - Using default tokenizer.\n",
      "Processing samples:  46%|████▌     | 46/100 [02:37<02:55,  3.26s/it]2025-07-15 12:57:42,229 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:57:43,333 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:57:43,336 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:57:43,336 - INFO - Using default tokenizer.\n",
      "Processing samples:  47%|████▋     | 47/100 [02:38<02:19,  2.63s/it]2025-07-15 12:57:43,376 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:57:44,960 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:57:44,963 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:57:44,963 - INFO - Using default tokenizer.\n",
      "Processing samples:  48%|████▊     | 48/100 [02:39<02:00,  2.33s/it]2025-07-15 12:57:45,004 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:57:46,353 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:57:46,355 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:57:46,355 - INFO - Using default tokenizer.\n",
      "Processing samples:  49%|████▉     | 49/100 [02:41<01:44,  2.05s/it]2025-07-15 12:57:46,396 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:57:47,545 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:57:47,548 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:57:47,548 - INFO - Using default tokenizer.\n",
      "2025-07-15 12:57:47,551 - INFO - Intermediate results saved at 50 samples\n",
      "Processing samples:  50%|█████     | 50/100 [02:42<01:29,  1.79s/it]2025-07-15 12:57:47,591 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:57:49,769 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:57:49,771 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:57:49,771 - INFO - Using default tokenizer.\n",
      "Processing samples:  51%|█████     | 51/100 [02:44<01:34,  1.92s/it]2025-07-15 12:57:49,812 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:57:50,929 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:57:50,932 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:57:50,932 - INFO - Using default tokenizer.\n",
      "Processing samples:  52%|█████▏    | 52/100 [02:45<01:21,  1.69s/it]2025-07-15 12:57:50,972 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:57:52,370 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:57:52,373 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:57:52,373 - INFO - Using default tokenizer.\n",
      "Processing samples:  53%|█████▎    | 53/100 [02:47<01:15,  1.62s/it]2025-07-15 12:57:52,414 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:57:53,658 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:57:53,661 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:57:53,661 - INFO - Using default tokenizer.\n",
      "Processing samples:  54%|█████▍    | 54/100 [02:48<01:09,  1.52s/it]2025-07-15 12:57:53,701 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:57:55,519 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:57:55,522 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:57:55,522 - INFO - Using default tokenizer.\n",
      "Processing samples:  55%|█████▌    | 55/100 [02:50<01:12,  1.62s/it]2025-07-15 12:57:55,562 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:57:57,129 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:57:57,131 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:57:57,131 - INFO - Using default tokenizer.\n",
      "Processing samples:  56%|█████▌    | 56/100 [02:52<01:11,  1.62s/it]2025-07-15 12:57:57,172 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:57:59,864 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:57:59,867 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:57:59,867 - INFO - Using default tokenizer.\n",
      "Processing samples:  57%|█████▋    | 57/100 [02:54<01:23,  1.95s/it]2025-07-15 12:57:59,907 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:58:01,255 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:58:01,257 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:58:01,258 - INFO - Using default tokenizer.\n",
      "Processing samples:  58%|█████▊    | 58/100 [02:56<01:14,  1.78s/it]2025-07-15 12:58:01,298 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:58:02,561 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:58:02,563 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:58:02,564 - INFO - Using default tokenizer.\n",
      "Processing samples:  59%|█████▉    | 59/100 [02:57<01:07,  1.64s/it]2025-07-15 12:58:02,604 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:58:07,506 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:58:07,507 - INFO - AFC remote call 1 is done.\n",
      "Processing samples:  60%|██████    | 60/100 [03:02<01:45,  2.63s/it]2025-07-15 12:58:07,548 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:58:09,885 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:58:09,887 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:58:09,887 - INFO - Using default tokenizer.\n",
      "Processing samples:  61%|██████    | 61/100 [03:04<01:39,  2.56s/it]2025-07-15 12:58:09,928 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:58:11,041 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:58:11,043 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:58:11,044 - INFO - Using default tokenizer.\n",
      "Processing samples:  62%|██████▏   | 62/100 [03:06<01:21,  2.14s/it]2025-07-15 12:58:11,084 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:58:16,813 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:58:16,815 - INFO - AFC remote call 1 is done.\n",
      "Processing samples:  63%|██████▎   | 63/100 [03:11<01:59,  3.23s/it]2025-07-15 12:58:16,856 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:58:18,472 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:58:18,475 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:58:18,475 - INFO - Using default tokenizer.\n",
      "Processing samples:  64%|██████▍   | 64/100 [03:13<01:39,  2.76s/it]2025-07-15 12:58:18,516 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:58:20,748 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:58:20,751 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:58:20,751 - INFO - Using default tokenizer.\n",
      "Processing samples:  65%|██████▌   | 65/100 [03:15<01:31,  2.61s/it]2025-07-15 12:58:20,791 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:58:36,259 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:58:36,262 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:58:36,262 - ERROR - Cannot get the response text.\n",
      "2025-07-15 12:58:36,262 - INFO - Using default tokenizer.\n",
      "Processing samples:  66%|██████▌   | 66/100 [03:31<03:40,  6.48s/it]2025-07-15 12:58:36,302 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:58:41,268 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:58:41,271 - INFO - AFC remote call 1 is done.\n",
      "Processing samples:  67%|██████▋   | 67/100 [03:36<03:19,  6.04s/it]2025-07-15 12:58:41,311 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:58:55,460 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:58:55,463 - INFO - AFC remote call 1 is done.\n",
      "Processing samples:  68%|██████▊   | 68/100 [03:50<04:31,  8.49s/it]2025-07-15 12:58:55,503 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:58:59,142 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:58:59,145 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:58:59,145 - INFO - Using default tokenizer.\n",
      "Processing samples:  69%|██████▉   | 69/100 [03:54<03:38,  7.04s/it]2025-07-15 12:58:59,186 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:59:04,953 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:59:04,956 - INFO - AFC remote call 1 is done.\n",
      "Processing samples:  70%|███████   | 70/100 [03:59<03:20,  6.67s/it]2025-07-15 12:59:04,996 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:59:08,883 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:59:08,885 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:59:08,885 - INFO - Using default tokenizer.\n",
      "Processing samples:  71%|███████   | 71/100 [04:03<02:49,  5.85s/it]2025-07-15 12:59:08,926 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:59:10,817 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:59:10,820 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:59:10,820 - INFO - Using default tokenizer.\n",
      "Processing samples:  72%|███████▏  | 72/100 [04:05<02:10,  4.68s/it]2025-07-15 12:59:10,860 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:59:14,013 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:59:14,016 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:59:14,016 - INFO - Using default tokenizer.\n",
      "Processing samples:  73%|███████▎  | 73/100 [04:09<01:54,  4.23s/it]2025-07-15 12:59:14,057 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:59:15,288 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:59:15,291 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:59:15,291 - INFO - Using default tokenizer.\n",
      "Processing samples:  74%|███████▍  | 74/100 [04:10<01:26,  3.34s/it]2025-07-15 12:59:15,331 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:59:16,793 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:59:16,796 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:59:16,796 - INFO - Using default tokenizer.\n",
      "Processing samples:  75%|███████▌  | 75/100 [04:11<01:09,  2.79s/it]2025-07-15 12:59:16,837 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:59:18,492 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:59:18,495 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:59:18,495 - INFO - Using default tokenizer.\n",
      "Processing samples:  76%|███████▌  | 76/100 [04:13<00:59,  2.46s/it]2025-07-15 12:59:18,535 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:59:21,116 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:59:21,118 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:59:21,118 - INFO - Using default tokenizer.\n",
      "Processing samples:  77%|███████▋  | 77/100 [04:16<00:57,  2.51s/it]2025-07-15 12:59:21,159 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:59:25,739 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:59:25,742 - INFO - AFC remote call 1 is done.\n",
      "Processing samples:  78%|███████▊  | 78/100 [04:20<01:09,  3.15s/it]2025-07-15 12:59:25,782 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:59:27,262 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:59:27,265 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:59:27,265 - INFO - Using default tokenizer.\n",
      "Processing samples:  79%|███████▉  | 79/100 [04:22<00:55,  2.66s/it]2025-07-15 12:59:27,305 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:59:28,948 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:59:28,950 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:59:28,950 - INFO - Using default tokenizer.\n",
      "Processing samples:  80%|████████  | 80/100 [04:23<00:47,  2.37s/it]2025-07-15 12:59:28,991 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:59:30,395 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:59:30,397 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:59:30,397 - INFO - Using default tokenizer.\n",
      "Processing samples:  81%|████████  | 81/100 [04:25<00:39,  2.09s/it]2025-07-15 12:59:30,438 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:59:32,152 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:59:32,154 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:59:32,154 - INFO - Using default tokenizer.\n",
      "Processing samples:  82%|████████▏ | 82/100 [04:27<00:35,  1.99s/it]2025-07-15 12:59:32,195 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:59:36,440 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:59:36,442 - INFO - AFC remote call 1 is done.\n",
      "Processing samples:  83%|████████▎ | 83/100 [04:31<00:45,  2.68s/it]2025-07-15 12:59:36,483 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:59:37,847 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:59:37,849 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:59:37,850 - INFO - Using default tokenizer.\n",
      "Processing samples:  84%|████████▍ | 84/100 [04:32<00:36,  2.30s/it]2025-07-15 12:59:37,890 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:59:39,563 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:59:39,566 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:59:39,566 - INFO - Using default tokenizer.\n",
      "Processing samples:  85%|████████▌ | 85/100 [04:34<00:31,  2.12s/it]2025-07-15 12:59:39,607 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:59:46,212 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:59:46,215 - INFO - AFC remote call 1 is done.\n",
      "Processing samples:  86%|████████▌ | 86/100 [04:41<00:48,  3.48s/it]2025-07-15 12:59:46,255 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:59:47,236 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:59:47,239 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:59:47,239 - INFO - Using default tokenizer.\n",
      "Processing samples:  87%|████████▋ | 87/100 [04:42<00:35,  2.74s/it]2025-07-15 12:59:47,280 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:59:48,869 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:59:48,871 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:59:48,871 - INFO - Using default tokenizer.\n",
      "Processing samples:  88%|████████▊ | 88/100 [04:43<00:28,  2.41s/it]2025-07-15 12:59:48,912 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 12:59:54,501 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 12:59:54,503 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 12:59:54,503 - INFO - Using default tokenizer.\n",
      "Processing samples:  89%|████████▉ | 89/100 [04:49<00:37,  3.38s/it]2025-07-15 12:59:54,543 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 13:00:00,207 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 13:00:00,210 - INFO - AFC remote call 1 is done.\n",
      "Processing samples:  90%|█████████ | 90/100 [04:55<00:40,  4.08s/it]2025-07-15 13:00:00,251 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 13:00:02,758 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 13:00:02,761 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 13:00:02,761 - INFO - Using default tokenizer.\n",
      "Processing samples:  91%|█████████ | 91/100 [04:57<00:32,  3.62s/it]2025-07-15 13:00:02,801 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 13:00:03,955 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 13:00:03,958 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 13:00:03,958 - INFO - Using default tokenizer.\n",
      "Processing samples:  92%|█████████▏| 92/100 [04:58<00:23,  2.89s/it]2025-07-15 13:00:03,999 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 13:00:05,688 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 13:00:05,690 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 13:00:05,690 - INFO - Using default tokenizer.\n",
      "Processing samples:  93%|█████████▎| 93/100 [05:00<00:17,  2.54s/it]2025-07-15 13:00:05,731 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 13:00:09,980 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 13:00:09,983 - INFO - AFC remote call 1 is done.\n",
      "Processing samples:  94%|█████████▍| 94/100 [05:05<00:18,  3.07s/it]2025-07-15 13:00:10,023 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 13:00:12,102 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 13:00:12,105 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 13:00:12,105 - INFO - Using default tokenizer.\n",
      "Processing samples:  95%|█████████▌| 95/100 [05:07<00:13,  2.78s/it]2025-07-15 13:00:12,145 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 13:00:14,768 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 13:00:14,771 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 13:00:14,771 - INFO - Using default tokenizer.\n",
      "Processing samples:  96%|█████████▌| 96/100 [05:09<00:10,  2.75s/it]2025-07-15 13:00:14,811 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 13:00:21,132 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 13:00:21,135 - INFO - AFC remote call 1 is done.\n",
      "Processing samples:  97%|█████████▋| 97/100 [05:16<00:11,  3.83s/it]2025-07-15 13:00:21,175 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 13:00:23,065 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 13:00:23,068 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 13:00:23,068 - INFO - Using default tokenizer.\n",
      "Processing samples:  98%|█████████▊| 98/100 [05:18<00:06,  3.26s/it]2025-07-15 13:00:23,108 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 13:00:24,452 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 13:00:24,455 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 13:00:24,455 - INFO - Using default tokenizer.\n",
      "Processing samples:  99%|█████████▉| 99/100 [05:19<00:02,  2.70s/it]2025-07-15 13:00:24,496 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-15 13:00:26,026 - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/vertex-workbench-notebook/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 13:00:26,028 - INFO - AFC remote call 1 is done.\n",
      "2025-07-15 13:00:26,028 - INFO - Using default tokenizer.\n",
      "2025-07-15 13:00:26,034 - INFO - Intermediate results saved at 100 samples\n",
      "Processing samples: 100%|██████████| 100/100 [05:21<00:00,  3.21s/it]\n",
      "2025-07-15 13:00:26,075 - INFO - Benchmark completed!\n",
      "2025-07-15 13:00:26,075 - INFO - Exact Match: 0.8800\n",
      "2025-07-15 13:00:26,075 - INFO - F1 Score: 0.9053\n",
      "2025-07-15 13:00:26,075 - INFO - ROUGE-1: 0.4100\n",
      "2025-07-15 13:00:26,075 - INFO - ROUGE-2: 0.2400\n",
      "2025-07-15 13:00:26,075 - INFO - ROUGE-L: 0.4100\n",
      "2025-07-15 13:00:26,075 - INFO - Impossible Accuracy: 1.0000\n",
      "2025-07-15 13:00:26,075 - INFO - Total time: 321.07 seconds\n",
      "2025-07-15 13:00:26,075 - INFO - Average time per sample: 3.211 seconds\n",
      "2025-07-15 13:00:26,075 - INFO - Metrics saved to: benchmark_results/klue_mrc_metrics_20250715_130026.json\n",
      "2025-07-15 13:00:26,081 - INFO - Detailed results saved to: benchmark_results/klue_mrc_results_20250715_130026.json\n",
      "2025-07-15 13:00:26,085 - INFO - Results saved as CSV: benchmark_results/klue_mrc_results_20250715_130026.csv\n",
      "2025-07-15 13:00:26,086 - INFO - Error analysis saved to: benchmark_results/klue_mrc_error_analysis_20250715_130026.txt\n",
      "============================================================\n",
      "KLUE Machine Reading Comprehension Benchmark Results\n",
      "============================================================\n",
      "Model: gemini-2.5-flash\n",
      "Platform: Google Cloud Vertex AI\n",
      "Project: vertex-workbench-notebook\n",
      "Location: us-central1\n",
      "Exact Match: 0.8800\n",
      "F1 Score: 0.9053\n",
      "ROUGE-1: 0.4100\n",
      "ROUGE-2: 0.2400\n",
      "ROUGE-L: 0.4100\n",
      "Impossible Accuracy: 1.0000\n",
      "Total Samples: 100\n",
      "Answerable Samples: 80\n",
      "Impossible Samples: 20\n",
      "Total Time: 321.07 seconds\n",
      "Average Time per Sample: 3.211 seconds\n",
      "Samples per Second: 0.31\n",
      "\n",
      "Answerable Questions Performance:\n",
      "  Exact Match: 0.8500\n",
      "  F1 Score: 0.8817\n",
      "  ROUGE-1: 0.2625\n",
      "  ROUGE-2: 0.0500\n",
      "  ROUGE-L: 0.2625\n",
      "  Sample Count: 80\n",
      "\n",
      "Impossible Questions Performance:\n",
      "  Accuracy: 1.0000\n",
      "  Correct: 20/20\n",
      "\n",
      "Error Analysis (showing first 5 errors):\n",
      "  1. Sample ID: klue-mrc-v1_dev_01835\n",
      "     Question: 가공하는데 몇 초밖에 걸리지 않는 물질은?...\n",
      "     Ground Truth: {'answer_start': [250], 'text': ['실리콘유']}\n",
      "     Predicted: 답을 찾을 수 없습니다...\n",
      "     Exact Match: 1.0000 | F1: 1.0000\n",
      "     ROUGE-1: 1.0000 | ROUGE-2: 1.0000 | ROUGE-L: 1.0000\n",
      "     Error: No response text\n",
      "\n",
      "  2. Sample ID: klue-mrc-v1_dev_00391\n",
      "     Question: 실리콘을 실리콘유로 만들기 위해 거치는 과정은?...\n",
      "     Ground Truth: {'answer_start': [188], 'text': ['실리콘']}\n",
      "     Predicted: 중합...\n",
      "     Exact Match: 0.0000 | F1: 0.0000\n",
      "     ROUGE-1: 0.0000 | ROUGE-2: 0.0000 | ROUGE-L: 0.0000\n",
      "\n",
      "  3. Sample ID: klue-mrc-v1_dev_04030\n",
      "     Question: 한국예술영재교육원 원장이 현재 학생을 가르치는 곳은?...\n",
      "     Ground Truth: {'answer_start': [167, 167, 211], 'text': ['한국예술종합학교 음악원', '한국예술종합학교', '한예종']}\n",
      "     Predicted: 한국예술영재교육원...\n",
      "     Exact Match: 0.0000 | F1: 0.0000\n",
      "     ROUGE-1: 0.0000 | ROUGE-2: 0.0000 | ROUGE-L: 0.0000\n",
      "\n",
      "  4. Sample ID: klue-mrc-v1_dev_00876\n",
      "     Question: 마르텔리노를 죽이겠다고 협박한 시장의 국적은?...\n",
      "     Ground Truth: {'answer_start': [29], 'text': ['독일']}\n",
      "     Predicted: 답을 찾을 수 없습니다...\n",
      "     Exact Match: 0.0000 | F1: 0.0000\n",
      "     ROUGE-1: 0.0000 | ROUGE-2: 0.0000 | ROUGE-L: 0.0000\n",
      "\n",
      "  5. Sample ID: klue-mrc-v1_dev_00460\n",
      "     Question: 튀니스의 왕이 딸의 정략결혼을 원활히 진행하기 위해 도움을 청한 사람은?...\n",
      "     Ground Truth: {'answer_start': [6, 320, 320], 'text': ['귈리엘모', '귈리엘모 왕', '귈리엘모']}\n",
      "     Predicted: 시칠리아의 귈리엘모 왕...\n",
      "     Exact Match: 0.0000 | F1: 0.8000\n",
      "     ROUGE-1: 0.0000 | ROUGE-2: 0.0000 | ROUGE-L: 0.0000\n",
      "\n",
      "Log files saved:\n",
      "  Full output: logs/klue_mrc_custom_100samples_20250715_125452.log\n",
      "  Errors only: logs/klue_mrc_custom_100samples_20250715_125452.err\n"
     ]
    }
   ],
   "source": [
    "!./run custom 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200194ca",
   "metadata": {},
   "source": [
    "### Baseline Performance\n",
    "To evaluate baseline performance, use the `./run full` command. Be aware that this process is time-consuming and may run overnight or for a full workday.\n",
    "\n",
    "To ensure uninterrupted execution, even if your terminal disconnects, we highly recommend running `./run full` within a `tmux` session.\n",
    "\n",
    "#### `tmux` Session Commands:\n",
    "- Create and start a new session: tmux new -s klue\n",
    "- Run the command within the session: ./run full\n",
    "- Detach from the session: Press Ctrl+b then d\n",
    "- Reattach to the klue session: tmux attach -t klue\n",
    "For more detailed information on tmux, refer to background_processing_with_tmux.md\n",
    "\n",
    "Alternatively, you can use the nohup command to run the process in the background, allowing it to continue after you log out of your session.\n",
    "\n",
    "# Running the command in the background is recommended.\n",
    "# Uncomment the following command if you still wish to run it in a cell\n",
    "#!./run full\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842935be-5252-4fba-bf65-7500b0e296f7",
   "metadata": {},
   "source": [
    "#### Test with All Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97db76d-c340-4e7b-9551-2e3ec24e064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./run full"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
